{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67a4370",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary of *â€œProof of the Central Limit Theoremâ€* (Steve Brunton)\n",
    "\n",
    "\n",
    "![Proof of CLT](../images/proof_of_clt.png)\n",
    "\n",
    "[ğŸï¸Steve Brunton: Proof of the Central Limit Theorem](https://www.youtube.com/watch?v=nWadI0_u6QU&list=PLMrJAkhIeNNR3sNYvfgiKgcStwuPSts9V&index=44)\n",
    "\n",
    "The video presents an intuitive, structured walkthrough of **why the Central Limit Theorem (CLT) is true**, focusing on the underlying mechanics rather than a purely formal proof.\n",
    "\n",
    "### ğŸ§© Core Ideas Covered\n",
    "- **Goal of the CLT:** Show that the sum (or average) of many independent, identically distributed random variables tends toward a **normal distribution**, regardless of the original distribution (as long as variance is finite).\n",
    "- **Key Strategy:**  \n",
    "  The proof uses **moment generating functions (MGFs)** or **characteristic functions** to track how distributions behave when summed.\n",
    "- **MGF Factorization:**  \n",
    "  Because independent variables have MGFs that multiply, the MGF of the normalized sum can be expanded using Taylor series.\n",
    "- **Normalization:**  \n",
    "  By centering and scaling the sum appropriately, higherâ€‘order terms vanish as $n \\to \\infty$, leaving the MGF of a standard normal distribution.\n",
    "- **Conclusion:**  \n",
    "  Since MGFs uniquely determine distributions, the limiting distribution must be **Gaussian**.\n",
    "\n",
    "### ğŸ§  Intuition Emphasized\n",
    "- Repeated addition â€œsmooths outâ€ irregularities in the original distribution.\n",
    "- The Gaussian emerges as the *universal attractor* for sums of independent noise sources.\n",
    "- The proof highlights how the second moment (variance) dominates the limiting behavior.\n",
    "\n",
    "### ğŸ“Œ What Youâ€™d Take Away\n",
    "- A conceptual and semiâ€‘rigorous proof of the CLT.\n",
    "- A deeper appreciation for why the normal distribution appears everywhere.\n",
    "- A sense of how MGFs provide a powerful lens for understanding convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f74ffa",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ Why divide by $ \\sigma \\sqrt{n} $ when normalizing the sum?\n",
    "\n",
    "Suppose you have i.i.d. random variables:\n",
    "\n",
    "$$\n",
    "X_1, X_2, \\dots, X_n\n",
    "$$\n",
    "\n",
    "each with:\n",
    "\n",
    "- mean $ \\mu $\n",
    "- variance $ \\sigma^2 $\n",
    "\n",
    "Define the **sum**:\n",
    "\n",
    "$$\n",
    "S_n = X_1 + X_2 + \\cdots + X_n\n",
    "$$\n",
    "\n",
    "Now look at its variance.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Œ Step 1: Variance of the sum\n",
    "\n",
    "Because the variables are independent:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(S_n) = \\mathrm{Var}(X_1) + \\cdots + \\mathrm{Var}(X_n)\n",
    "= n \\sigma^2\n",
    "$$\n",
    "\n",
    "So the **standard deviation** of the sum is:\n",
    "\n",
    "$$\n",
    "\\sqrt{\\mathrm{Var}(S_n)} = \\sigma \\sqrt{n}\n",
    "$$\n",
    "\n",
    "This is the key fact.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Œ Step 2: What does â€œnormalizeâ€ mean?\n",
    "\n",
    "To normalize a random variable so that it has:\n",
    "\n",
    "- mean $0$\n",
    "- standard deviation $1$\n",
    "\n",
    "you subtract its mean and divide by its standard deviation.\n",
    "\n",
    "For the sum $S_n$:\n",
    "\n",
    "- mean is $n\\mu$\n",
    "- standard deviation is $ \\sigma \\sqrt{n} $\n",
    "\n",
    "So the normalized version is:\n",
    "\n",
    "$$\n",
    "\\frac{S_n - n\\mu}{\\sigma \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "This is exactly the expression that appears in the CLT.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Œ Step 3: Why this scaling specifically?\n",
    "\n",
    "Because the CLT is about the **shape** of the distribution of the sum as $n$ grows.\n",
    "\n",
    "If you didnâ€™t divide by $ \\sigma \\sqrt{n} $:\n",
    "\n",
    "- the variance would blow up like $n$\n",
    "- the distribution would spread wider and wider\n",
    "- youâ€™d never get a stable limiting distribution\n",
    "\n",
    "Dividing by $ \\sigma \\sqrt{n} $ rescales the sum so that its variance becomes:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}\\!\\left( \\frac{S_n}{\\sigma \\sqrt{n}} \\right)\n",
    "= \\frac{n\\sigma^2}{\\sigma^2 n}\n",
    "= 1\n",
    "$$\n",
    "\n",
    "This keeps the distribution at a fixed â€œwidth,â€ allowing it to converge to the standard normal.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ Intuition in one sentence\n",
    "\n",
    "**The sum gets $n$ times more variable, so you need to divide by $ \\sqrt{n} $ to keep the variability constant.**\n",
    "\n",
    "The extra $ \\sigma $ just adjusts for the scale of the original variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888022d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Showing how $m'(0) = \\mathbb{E}[X]$\n",
    "\n",
    "We start with the **moment generating function** of a random variable $X$:\n",
    "$$\n",
    "m(t) = \\mathbb{E}\\big[e^{tX}\\big].\n",
    "$$\n",
    "\n",
    "Differentiate with respect to $t$:\n",
    "$$\n",
    "m'(t) = \\frac{d}{dt}\\mathbb{E}\\big[e^{tX}\\big] = \\mathbb{E}\\big[X e^{tX}\\big],\n",
    "$$\n",
    "where weâ€™ve moved the derivative inside the expectation (this is standard under mild regularity conditions).\n",
    "\n",
    "Now evaluate at $t = 0$:\n",
    "$$\n",
    "m'(0) = \\mathbb{E}\\big[X e^{0\\cdot X}\\big] = \\mathbb{E}[X \\cdot 1] = \\mathbb{E}[X].\n",
    "$$\n",
    "\n",
    "So in general,\n",
    "$$\n",
    "m'(0) = \\mathbb{E}[X],\n",
    "$$\n",
    "i.e., **the first derivative of the MGF at 0 is the mean** of $X$.\n",
    "\n",
    "In Steveâ€™s setup, the random variables are assumed to have **mean 0**, so\n",
    "$$\n",
    "\\mathbb{E}[X] = 0 \\quad \\Rightarrow \\quad m'(0) = 0.\n",
    "$$\n",
    "\n",
    "Then in the Taylor expansion\n",
    "$$\n",
    "m(t) = m(0) + t\\,m'(0) + \\frac{t^2}{2}m''(0) + \\cdots,\n",
    "$$\n",
    "the linear term becomes\n",
    "$$\n",
    "t\\,m'(0) = t \\cdot 0 = 0,\n",
    "$$\n",
    "which is why he can drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9872ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ Show how $\\frac{t^2}{2}\\, m''(0) \\;=\\; \\frac{t^2 \\sigma^2}{2}$\n",
    "Show that  \n",
    "$$\n",
    "\\frac{t^2}{2}\\, m''(0) \\;=\\; \\frac{t^2 \\sigma^2}{2}.\n",
    "$$\n",
    "\n",
    "So we need to understand **what $m''(0)$ equals**.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ” Step 1 â€” Start from the definition of the MGF  \n",
    "For a random variable $X$, the moment generating function is  \n",
    "$$\n",
    "m(t) = \\mathbb{E}[e^{tX}].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ” Step 2 â€” Differentiate twice  \n",
    "First derivative:  \n",
    "$$\n",
    "m'(t) = \\mathbb{E}[X e^{tX}].\n",
    "$$\n",
    "\n",
    "Second derivative:  \n",
    "$$\n",
    "m''(t) = \\mathbb{E}[X^2 e^{tX}].\n",
    "$$\n",
    "\n",
    "This comes from differentiating inside the expectation again.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ” Step 3 â€” Evaluate at $t = 0$  \n",
    "Plugging in $t = 0$:\n",
    "\n",
    "$$\n",
    "m''(0) = \\mathbb{E}[X^2 e^{0\\cdot X}]\n",
    "       = \\mathbb{E}[X^2].\n",
    "$$\n",
    "\n",
    "And of course:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2.\n",
    "$$\n",
    "\n",
    "But in Steveâ€™s setup, the mean is **0**, so:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\operatorname{Var}(X) = \\sigma^2.\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "m''(0) = \\sigma^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ‰ Final Step â€” Plug into the Taylor term  \n",
    "The secondâ€‘order Taylor term is:\n",
    "\n",
    "$$\n",
    "\\frac{t^2}{2} m''(0)\n",
    "  = \\frac{t^2}{2} \\sigma^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcdae8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ± What Steve Is Doing in the Taylor Expansion\n",
    "\n",
    "He expands the MGF $m(t)$ around $t = 0$:\n",
    "\n",
    "$$\n",
    "m(t) = m(0) + t m'(0) + \\frac{t^2}{2} m''(0) + \\text{higherâ€‘order terms}.\n",
    "$$\n",
    "\n",
    "Since  \n",
    "- $m(0) = 1$,  \n",
    "- $m'(0) = 0$ (mean is zero),  \n",
    "- $m''(0) = \\sigma^2$,\n",
    "\n",
    "the expansion becomes:\n",
    "\n",
    "$$\n",
    "m(t) = 1 + \\frac{t^2 \\sigma^2}{2} + \\text{(thirdâ€‘order and higher terms)}.\n",
    "$$\n",
    "\n",
    "Now the question is: **what happens to those thirdâ€‘order and higher terms?**\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ¿ What â€œlittleâ€‘oâ€ Means\n",
    "\n",
    "The notation  \n",
    "$$\n",
    "o(t^2)\n",
    "$$  \n",
    "means:\n",
    "\n",
    "> A function that becomes *negligible compared to $t^2$* as $t \\to 0$.\n",
    "\n",
    "Formally:\n",
    "$$\n",
    "\\lim_{t \\to 0} \\frac{o(t^2)}{t^2} = 0.\n",
    "$$\n",
    "\n",
    "So if you divide the remainder by $t^2$, it goes to zero.\n",
    "\n",
    "This is stronger than just saying â€œsmallâ€ â€” it says â€œ*vanishes faster than $t^2$*.â€\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ³ Why the Thirdâ€‘Order Term Becomes $o(t^2)$\n",
    "\n",
    "The next term in the Taylor expansion is:\n",
    "\n",
    "$$\n",
    "\\frac{t^3}{6} m^{(3)}(\\xi)\n",
    "$$\n",
    "\n",
    "for some $\\xi$ between $0$ and $t$ (this is the Lagrange form of the remainder).\n",
    "\n",
    "Now look at how it behaves relative to $t^2$:\n",
    "\n",
    "$$\n",
    "\\frac{\\frac{t^3}{6} m^{(3)}(\\xi)}{t^2}\n",
    "= \\frac{t}{6} m^{(3)}(\\xi).\n",
    "$$\n",
    "\n",
    "As $t \\to 0$,  \n",
    "- $t \\to 0$,  \n",
    "- $m^{(3)}(\\xi)$ stays finite (MGFs are smooth near 0).\n",
    "\n",
    "So the whole expression goes to **0**.\n",
    "\n",
    "That is exactly the definition of:\n",
    "\n",
    "$$\n",
    "\\frac{t^3}{6} m^{(3)}(\\xi) = o(t^2).\n",
    "$$\n",
    "\n",
    "And the same logic applies to all higherâ€‘order terms (they vanish even faster).\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ Putting It All Together\n",
    "\n",
    "So the MGF expansion becomes:\n",
    "\n",
    "$$\n",
    "m(t) = 1 + \\frac{t^2 \\sigma^2}{2} + o(t^2).\n",
    "$$\n",
    "\n",
    "This is the compact way of saying:\n",
    "\n",
    "> â€œEverything beyond the quadratic term becomes negligible compared to $t^2$ as $t \\to 0$.â€\n",
    "\n",
    "This is exactly what Steve uses when he plugs in  \n",
    "$$\n",
    "t = \\frac{s}{\\sigma\\sqrt{n}}\n",
    "$$\n",
    "and lets $n \\to \\infty$.  \n",
    "The littleâ€‘o term shrinks away, leaving only the Gaussian MGF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ed9af",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Great question, Peter â€” this is exactly the right instinct. The whole point of *littleâ€‘o* notation is to **compare the size of two functions**, and the way we compare them is by dividing one by the other.\n",
    "\n",
    "Letâ€™s build the intuition step by step.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ± What â€œlittleâ€‘oâ€ Formally Means\n",
    "\n",
    "Saying  \n",
    "$$\n",
    "r(t) = o(t^2) \\quad \\text{as } t \\to 0\n",
    "$$  \n",
    "means:\n",
    "\n",
    "$$\n",
    "\\lim_{t\\to 0} \\frac{r(t)}{t^2} = 0.\n",
    "$$\n",
    "\n",
    "So the ratio goes to zero.\n",
    "\n",
    "But why *this* ratio?\n",
    "\n",
    "Because littleâ€‘o is all about **relative size**.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ¿ Why We Divide by $t^2$\n",
    "\n",
    "Think of it like comparing two runners:\n",
    "\n",
    "- Runner A: speed = $t^2$  \n",
    "- Runner B: speed = $r(t)$\n",
    "\n",
    "To see whether B is â€œnegligible compared toâ€ A, you look at:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{speed of B}}{\\text{speed of A}}.\n",
    "$$\n",
    "\n",
    "If this ratio â†’ 0, then B is falling behind so fast that A completely dominates.\n",
    "\n",
    "Thatâ€™s exactly whatâ€™s happening with functions.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ³ A Concrete Example\n",
    "\n",
    "Suppose  \n",
    "$$\n",
    "r(t) = t^3.\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{r(t)}{t^2} = \\frac{t^3}{t^2} = t.\n",
    "$$\n",
    "\n",
    "As $t \\to 0$, this goes to 0.\n",
    "\n",
    "So $t^3$ is *littleâ€‘o* of $t^2$:\n",
    "\n",
    "$$\n",
    "t^3 = o(t^2).\n",
    "$$\n",
    "\n",
    "This matches intuition: $t^3$ shrinks faster than $t^2$.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ² What If We Divided by Something Else?\n",
    "\n",
    "If you divided by $t^3$ instead:\n",
    "\n",
    "$$\n",
    "\\frac{t^3}{t^3} = 1,\n",
    "$$\n",
    "\n",
    "which does **not** go to zero.  \n",
    "So relative to $t^3$, the function is *not* negligible.\n",
    "\n",
    "If you divided by $t$:\n",
    "\n",
    "$$\n",
    "\\frac{t^3}{t} = t^2,\n",
    "$$\n",
    "\n",
    "which *does* go to zero â€” meaning $t^3$ is also negligible compared to $t$.\n",
    "\n",
    "So the denominator you choose determines **what youâ€™re comparing against**.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ Why $t^2$ Specifically in the CLT Proof?\n",
    "\n",
    "Because the Taylor expansion of the MGF is:\n",
    "\n",
    "$$\n",
    "m(t) = 1 + 0\\cdot t + \\frac{\\sigma^2}{2} t^2 + \\text{higherâ€‘order terms}.\n",
    "$$\n",
    "\n",
    "The quadratic term is the **last one we keep**.\n",
    "\n",
    "Everything beyond it must be shown to be â€œnegligible compared to $t^2$.â€\n",
    "\n",
    "So we check:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{remainder}}{t^2} \\to 0.\n",
    "$$\n",
    "\n",
    "This is exactly the definition of:\n",
    "\n",
    "$$\n",
    "\\text{remainder} = o(t^2).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒˆ Intuition in One Sentence\n",
    "\n",
    "We divide by $t^2$ because we want to know:\n",
    "\n",
    "> â€œDoes the remainder shrink *faster* than the $t^2$ term weâ€™re keeping?â€\n",
    "\n",
    "If yes, then itâ€™s negligible â€” and littleâ€‘o notation captures that idea perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3d416",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ **1. Why does the MGF Taylor expansion use the limit as $t \\to 0$?**\n",
    "\n",
    "Yes â€” the reason is **precisely** that *all moments of a random variable are encoded in the derivatives of the MGF at $t = 0$*.\n",
    "\n",
    "The MGF is  \n",
    "$$\n",
    "m(t) = \\mathbb{E}[e^{tX}].\n",
    "$$\n",
    "\n",
    "Its derivatives at 0 give the moments:\n",
    "\n",
    "- $m(0) = 1$\n",
    "- $m'(0) = \\mathbb{E}[X]$\n",
    "- $m''(0) = \\mathbb{E}[X^2]$\n",
    "- $m^{(k)}(0) = \\mathbb{E}[X^k]$\n",
    "\n",
    "So if you want to approximate the MGF using its moments, you *must* expand around $t = 0$. Thatâ€™s the only point where the derivatives correspond directly to the moments.\n",
    "\n",
    "This is why the Taylor expansion is taken as $t \\to 0$, and why the remainder is expressed as $o(t^2)$ *as $t \\to 0$*.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ± **2. Is littleâ€‘o defined only for limits approaching 0?**\n",
    "\n",
    "Not at all â€” littleâ€‘o works for **any limit point**.\n",
    "\n",
    "The general definition is:\n",
    "\n",
    "$$\n",
    "f(x) = o(g(x)) \\quad \\text{as } x \\to a\n",
    "$$\n",
    "\n",
    "means\n",
    "\n",
    "$$\n",
    "\\lim_{x \\to a} \\frac{f(x)}{g(x)} = 0.\n",
    "$$\n",
    "\n",
    "So you can have:\n",
    "\n",
    "- $f(x) = o(g(x))$ as $x \\to 0$\n",
    "- $f(x) = o(g(x))$ as $x \\to \\infty$\n",
    "- $f(x) = o(g(x))$ as $x \\to 5$\n",
    "- $f(t) = o(g(t))$ as $t \\to t_0$\n",
    "\n",
    "Itâ€™s completely general.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒ¿ **3. So why does the CLT proof specifically use littleâ€‘o as $t \\to 0$?**\n",
    "\n",
    "Because the Taylor expansion of the MGF is only valid *near* $t = 0$, and the coefficients of the expansion are the moments evaluated at 0.\n",
    "\n",
    "The CLT proof uses:\n",
    "\n",
    "$$\n",
    "m(t) = 1 + \\frac{\\sigma^2}{2} t^2 + o(t^2) \\quad \\text{as } t \\to 0.\n",
    "$$\n",
    "\n",
    "Then it substitutes:\n",
    "\n",
    "$$\n",
    "t = \\frac{s}{\\sigma\\sqrt{n}}.\n",
    "$$\n",
    "\n",
    "As $n \\to \\infty$, this substituted $t$ automatically goes to 0, which is exactly the regime where the Taylor expansion is valid.\n",
    "\n",
    "So the whole proof hinges on:\n",
    "\n",
    "- expanding the MGF around 0,\n",
    "- showing the remainder is negligible compared to $t^2$,\n",
    "- then letting $t$ shrink to 0 via the normalization.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ **4. Intuition in one sentence**\n",
    "\n",
    "We expand the MGF at $t=0$ because thatâ€™s where the moments live, and littleâ€‘o can be used at any limit point â€” but in the CLT proof, the relevant limit is $t \\to 0$ because the normalization forces it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

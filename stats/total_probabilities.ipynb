{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3863b48",
   "metadata": {},
   "source": [
    "# üéØ The Law of Total Probability  \n",
    "The **Law of Total Probability** tells you how to compute the probability of an event by *breaking the sample space into parts* and adding up the contributions from each part.\n",
    "\n",
    "It‚Äôs like saying:  \n",
    "> ‚ÄúIf an event $A$ can happen for different reasons, add up the probability of each reason *weighted* by how likely that reason is.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "# üß© Formal Definition  \n",
    "Suppose the sample space is partitioned into mutually exclusive and exhaustive events:\n",
    "\n",
    "$$\n",
    "B_1, B_2, \\ldots, B_n\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "- They **don‚Äôt overlap**: $B_i \\cap B_j = \\varnothing$ for $i \\neq j$  \n",
    "- They **cover everything**: $B_1 \\cup \\cdots \\cup B_n = \\Omega$\n",
    "\n",
    "Then for any event $A$:\n",
    "\n",
    "$$\n",
    "P(A) = \\sum_{i=1}^{n} P(A \\mid B_i)\\, P(B_i)\n",
    "$$\n",
    "\n",
    "This is the Law of Total Probability.\n",
    "\n",
    "---\n",
    "\n",
    "# üîç Intuition  \n",
    "Think of the $B_i$ as ‚Äúscenarios‚Äù or ‚Äúworlds.‚Äù  \n",
    "In each world, the probability of $A$ might be different.\n",
    "\n",
    "So you:\n",
    "\n",
    "1. Look at each world $B_i$  \n",
    "2. Ask: ‚ÄúWhat‚Äôs the chance of $A$ *if* we‚Äôre in this world?‚Äù ‚Üí $P(A \\mid B_i)$  \n",
    "3. Weight it by how likely that world is ‚Üí $P(B_i)$  \n",
    "4. Add them up\n",
    "\n",
    "It‚Äôs a weighted average of conditional probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "# üé® Visual Breakdown (your style)\n",
    "\n",
    "Imagine a tree diagram:\n",
    "\n",
    "```\n",
    "          Start\n",
    "         /  |  \\\n",
    "      B1   B2  ... Bn\n",
    "      |     |        |\n",
    "   A or not A   A or not A\n",
    "```\n",
    "\n",
    "The probability of reaching $A$ is:\n",
    "\n",
    "$$\n",
    "P(A) = P(B_1)P(A|B_1) + P(B_2)P(A|B_2) + \\cdots + P(B_n)P(A|B_n)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# üçé Example (simple but powerful)\n",
    "\n",
    "A medical test works differently depending on whether a person is high‚Äërisk or low‚Äërisk.\n",
    "\n",
    "- $B_1$: high‚Äërisk group (20% of population)  \n",
    "- $B_2$: low‚Äërisk group (80% of population)\n",
    "\n",
    "Test positive rates:\n",
    "\n",
    "- $P(\\text{positive} \\mid B_1) = 0.30$  \n",
    "- $P(\\text{positive} \\mid B_2) = 0.05$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "P(\\text{positive}) = 0.30(0.20) + 0.05(0.80) = 0.06 + 0.04 = 0.10\n",
    "$$\n",
    "\n",
    "So overall, 10% of the population tests positive.\n",
    "\n",
    "---\n",
    "\n",
    "# üîó Why it matters  \n",
    "This law is the backbone of:\n",
    "\n",
    "- Bayesian inference  \n",
    "- Decision theory  \n",
    "- Hidden Markov models  \n",
    "- Reliability engineering  \n",
    "- Machine learning classification  \n",
    "- Medical testing and diagnostics  \n",
    "\n",
    "It‚Äôs one of those deceptively simple rules that quietly powers half of probability theory."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2287bff",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Notes on Variance and Standard Deviation\n",
    "\n",
    "## ğŸ¯ **What They Measure**\n",
    "Both **variance** and **standard deviation** quantify **spread** â€” how far data points tend to be from the mean.\n",
    "\n",
    "- If the spread is small â†’ data is tightly clustered.\n",
    "- If the spread is large â†’ data is more dispersed.\n",
    "\n",
    "They are foundational because almost every statistical method (confidence intervals, regression, hypothesis tests, probability distributions) depends on understanding variability.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ”¢ **Variance**\n",
    "\n",
    "## âœ¨ Definition\n",
    "Variance measures the **average squared deviation** from the mean.\n",
    "\n",
    "For a population:\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "For a sample:\n",
    "$$\n",
    "s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\n",
    "$$\n",
    "\n",
    "### Why square the deviations?\n",
    "- Squaring prevents positive and negative deviations from canceling out.\n",
    "- It penalizes large deviations more heavily.\n",
    "- It gives variance nice mathematical properties (especially in probability theory).\n",
    "\n",
    "### Why divide by $n-1$ for samples?\n",
    "This is **Besselâ€™s correction**.  \n",
    "It corrects the bias that arises because the sample mean $\\bar{x}$ is itself estimated from the data.  \n",
    "Using $n-1$ makes $s^2$ an **unbiased estimator** of the population variance.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“ **Standard Deviation**\n",
    "\n",
    "## âœ¨ Definition\n",
    "Standard deviation is the **square root of variance**:\n",
    "\n",
    "Population:\n",
    "$$\n",
    "\\sigma = \\sqrt{\\sigma^2}\n",
    "$$\n",
    "\n",
    "Sample:\n",
    "$$\n",
    "s = \\sqrt{s^2}\n",
    "$$\n",
    "\n",
    "### Why take the square root?\n",
    "- Variance is in **squared units** (e.g., metersÂ², dollarsÂ²).\n",
    "- Standard deviation returns to the **original units**, making it more interpretable.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§  **Intuition**\n",
    "\n",
    "Imagine data points as people standing around a flagpole (the mean):\n",
    "\n",
    "- If everyone stands close â†’ low variance, low standard deviation.\n",
    "- If people spread out â†’ high variance, high standard deviation.\n",
    "\n",
    "Variance = average squared distance from the pole  \n",
    "Standard deviation = average distance from the pole (in original units)\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Š **Properties**\n",
    "\n",
    "### âœ” Always non-negative  \n",
    "Variance and SD are never negative because squared deviations are never negative.\n",
    "\n",
    "### âœ” Sensitive to outliers  \n",
    "A single extreme value can dramatically increase variance and SD.\n",
    "\n",
    "### âœ” Additivity for independent variables  \n",
    "If $X$ and $Y$ are independent:\n",
    "$$\n",
    "\\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y)\n",
    "$$\n",
    "\n",
    "This is crucial in probability, error propagation, and the Central Limit Theorem.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“ˆ **Worked Example**\n",
    "\n",
    "Data: $2, 4, 4, 4, 5, 5, 7, 9$\n",
    "\n",
    "1. Mean:\n",
    "$$\n",
    "\\bar{x} = 5\n",
    "$$\n",
    "\n",
    "2. Deviations:  \n",
    "$-3, -1, -1, -1, 0, 0, 2, 4$\n",
    "\n",
    "3. Squared deviations:  \n",
    "$9, 1, 1, 1, 0, 0, 4, 16$\n",
    "\n",
    "4. Variance (population):\n",
    "$$\n",
    "\\sigma^2 = \\frac{32}{8} = 4\n",
    "$$\n",
    "\n",
    "5. Standard deviation:\n",
    "$$\n",
    "\\sigma = \\sqrt{4} = 2\n",
    "$$\n",
    "\n",
    "Interpretation:  \n",
    "On average, data points lie about **2 units** from the mean.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§© **When to Use Which**\n",
    "\n",
    "| Situation | Use |\n",
    "|----------|-----|\n",
    "| You have the entire population | Population variance/SD ($\\sigma^2, \\sigma$) |\n",
    "| You have a sample and want to infer about a population | Sample variance/SD ($s^2, s$) |\n",
    "| You need interpretability | Standard deviation |\n",
    "| You need mathematical convenience (e.g., in proofs) | Variance |\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ **Key Takeaways**\n",
    "\n",
    "- Variance = average squared deviation  \n",
    "- Standard deviation = square root of variance  \n",
    "- SD is more interpretable; variance is more mathematically convenient  \n",
    "- Both measure spread, not central tendency  \n",
    "- Sample formulas use $n-1$ to correct bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608815d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ The Shortcut Formula for Variance\n",
    "The â€œshortcutâ€ (also called the **computational formula**) for the variance of a random variable $X$ is:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n",
    "$$\n",
    "\n",
    "Itâ€™s elegant because instead of computing $\\mathbb{E}[(X - \\mu)^2]$ directly â€” which can be messy â€” you compute two simpler expectations.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Why It Works (Derivation)\n",
    "Start from the definition of variance:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[(X - \\mu)^2]\n",
    "$$\n",
    "\n",
    "Expand the square:\n",
    "\n",
    "$$\n",
    "(X - \\mu)^2 = X^2 - 2\\mu X + \\mu^2\n",
    "$$\n",
    "\n",
    "Now take expectations term-by-term (linearity of expectation is doing the heavy lifting):\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[X^2] - 2\\mu \\mathbb{E}[X] + \\mathbb{E}[\\mu^2]\n",
    "$$\n",
    "\n",
    "But:\n",
    "\n",
    "- $\\mu = \\mathbb{E}[X]$\n",
    "- $\\mathbb{E}[X] = \\mu$\n",
    "- $\\mathbb{E}[\\mu^2] = \\mu^2$ because $\\mu$ is a constant\n",
    "\n",
    "So substitute:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[X^2] - 2\\mu^2 + \\mu^2\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[X^2] - \\mu^2\n",
    "$$\n",
    "\n",
    "And since $\\mu = \\mathbb{E}[X]$:\n",
    "\n",
    "$$\n",
    "\\boxed{\\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Why This Feels Like a â€œShortcutâ€\n",
    "Computing variance directly requires:\n",
    "\n",
    "- computing the mean,\n",
    "- subtracting it from every value,\n",
    "- squaring the deviations,\n",
    "- then averaging.\n",
    "\n",
    "The shortcut avoids the deviations entirely. For discrete distributions:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum x p(x), \\qquad \\mathbb{E}[X^2] = \\sum x^2 p(x)\n",
    "$$\n",
    "\n",
    "For continuous distributions:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int x f(x)\\,dx, \\qquad \\mathbb{E}[X^2] = \\int x^2 f(x)\\,dx\n",
    "$$\n",
    "\n",
    "Both are usually much easier than integrating or summing $(x - \\mu)^2$.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŸ Intuition (the part people often miss)\n",
    "Variance measures â€œspread,â€ but the shortcut formula shows something deeper:\n",
    "\n",
    "- $\\mathbb{E}[X^2]$ captures the *raw magnitude* of the distribution.\n",
    "- $(\\mathbb{E}[X])^2$ captures the *central tendency*.\n",
    "- Their difference isolates the *spread*.\n",
    "\n",
    "Itâ€™s like saying:  \n",
    "**â€œHow big are the values on average, minus how big the average value is.â€**\n",
    "\n",
    "That gap is the variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3d0d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ The difference between $\\mathbb{E}[X]$ and $\\mu$\n",
    "- **$ \\mathbb{E}[X] $** is an *operation*: â€œtake the expectation of the random variable $X$.â€\n",
    "- **$ \\mu $** is a *symbol*: a constant that represents the result of that operation.\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\mu = \\mathbb{E}[X]\n",
    "$$\n",
    "\n",
    "Theyâ€™re equal, but theyâ€™re not the same *kind* of thing.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§  Why We Need Both\n",
    "\n",
    "## 1. **$ \\mathbb{E}[X] $ emphasizes the process**\n",
    "When you write:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "$$\n",
    "\n",
    "youâ€™re explicitly saying:\n",
    "\n",
    "- â€œApply the expectation operator to the random variable $X$.â€\n",
    "- â€œThis depends on the distribution of $X$.â€\n",
    "- â€œThis is something we can compute.â€\n",
    "\n",
    "Itâ€™s like writing â€œdifferentiate $f(x)$â€ vs. â€œthe derivative $f'(x)$.â€\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **$ \\mu $ emphasizes the result**\n",
    "Once the expectation is computed, we often want to treat it as a constant:\n",
    "\n",
    "- in algebraic manipulations,\n",
    "- in formulas like variance,\n",
    "- in proofs,\n",
    "- in parameterized families of distributions.\n",
    "\n",
    "For example, in a normal distribution:\n",
    "\n",
    "$$\n",
    "X \\sim \\mathcal{N}(\\mu, \\sigma^2)\n",
    "$$\n",
    "\n",
    "the symbol $ \\mu $ is a *parameter*, not an operator.\n",
    "\n",
    "Writing $ \\mathbb{E}[X] $ there would be awkward and confusing."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
